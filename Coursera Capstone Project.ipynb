{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Classification with Python"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import itertools\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Download and read the dataset"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.read_csv('loan_train.csv')\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Convert to date time object"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['effective_date'] = pd.to_datetime(df['effective_date'])\ndf['due_date'] = pd.to_datetime(df['due_date'])\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data visulisation and analysis"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['loan_status'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['Principal'].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "g = sns.FacetGrid(df, col='Gender', hue='loan_status', col_wrap=2)\ng.map(plt.hist, 'Principal', bins=np.linspace(0, df.Principal.max(), 10), ec='k')\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "g = sns.FacetGrid(df, col='Gender', hue='loan_status', col_wrap=2)\ng.map(plt.hist, 'age', bins=np.linspace(df.age.min(), df.age.max(), 10), ec='k')\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Pre-processing: Feature selection/extraction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## The day of the week people get the loan"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['dayofweek'] = df['effective_date'].dt.dayofweek\n\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=np.linspace(0,6,7), ec=\"k\") # Monday=0, Sunday=6\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "According to the histogram above, people who get the loan on weekends seem more likely to default on loans, so we divide the days of week into two groups: 1 stands for Friday, Satturday, and Sunday, and 0 stands for the rest"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x > 3) else 0)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Convert Categorical features to numerical values"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "convert male to 0 and female to 1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['Gender'].replace(to_replace = ['male', 'female'], value = [0, 1], inplace = True)\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Feature before One Hot Encoding"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Feature = pd.concat([Feature, pd.get_dummies(df['education'])], axis = 1)\nFeature.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Feature selection"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X = Feature\nX[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y = df['loan_status'].values\ny[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Train Test Split"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Normalise data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Data Standardisation give data zero mean and unit variance (technically should be done after train test split )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Classification"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## K Nearest Neighbor"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.neighbors import KNeighborsClassifier"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Training"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Lets start the algorithm with k=4 for now."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Predicting"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Use the model to predict the test set."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "yhat = neigh.predict(X_test)\nyhat[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Accuracy evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ks = 20\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.1)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Rebuild the model with optimal K"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "k = mean_acc.argmax()+1\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "yhat = neigh.predict(X_test)\nyhat[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Accuracy evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import classification_report, confusion_matrix"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=['COLLECTION', 'PAIDOFF'])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['COLLECTION', 'PAIDOFF'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Jaccard index"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### F1-score"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted') "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Decision Tree"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.tree import DecisionTreeClassifier"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "loan_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\nloan_tree"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "loan_tree.fit(X_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pred_tree = loan_tree.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print (pred_tree[0:5])\nprint (y_test[0:5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, pred_tree))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Confusion matrix"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, pred_tree, labels=['COLLECTION', 'PAIDOFF'])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, pred_tree))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['COLLECTION', 'PAIDOFF'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Jaccard index"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "jaccard_similarity_score(y_test, pred_tree)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### F1-score"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "f1_score(y_test, pred_tree, average='weighted') "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Support Vector Machine"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn import svm\nloan = svm.SVC(kernel='rbf')\nloan.fit(X_train, y_train) "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y_svm = loan.predict(X_test)\ny_svm[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Confusion matrix"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_svm, labels=['COLLECTION', 'PAIDOFF'])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, y_svm))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['COLLECTION', 'PAIDOFF'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Jaccard index"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "jaccard_similarity_score(y_test, y_svm)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### F1-score"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "f1_score(y_test, y_svm, average='weighted') "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.linear_model import LogisticRegression"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y_LR = LR.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y_LR_prob = LR.predict_proba(X_test)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Confusion matrix"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_LR, labels=['COLLECTION', 'PAIDOFF'])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, y_LR))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['COLLECTION', 'PAIDOFF'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Jaccard index"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "jaccard_similarity_score(y_test, y_LR)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## F1-score"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "f1_score(y_test, y_LR, average='weighted') "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## log loss"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import log_loss\nlog_loss(y_test, y_LR_prob)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Model Evaluation using Test set"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_test = pd.read_csv('loan_test.csv')\ndf_test.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# convert to date time object\ndf_test['effective_date'] = pd.to_datetime(df_test['effective_date'])\ndf_test['due_date'] = pd.to_datetime(df_test['due_date'])\n\ndf_test['dayofweek'] = df_test['effective_date'].dt.dayofweek\ndf_test['weekend'] = df_test['dayofweek'].apply(lambda x: 1 if (x > 3) else 0)\ndf_test['Gender'].replace(to_replace = ['male', 'female'], value = [0, 1], inplace = True)\n\nFeature_test = df_test[['Principal','terms','age','Gender','weekend']]\n\nFeature_test = pd.concat([Feature_test, pd.get_dummies(df_test['education'])], axis = 1)\n\nFeature_test.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X_testset = preprocessing.StandardScaler().fit(Feature_test).transform(Feature_test)\nX_testset[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y_testset = df_test['loan_status'].values\ny_testset[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## KNN Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "yhat_test = neigh.predict(X_testset)\nprint('KNN Jaccard index: {}'.format(jaccard_similarity_score(y_testset, yhat_test)))\nprint('KNN F1-score: {}'.format(f1_score(y_testset, yhat_test, average='weighted')))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Decision Tree Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tree_test = loan_tree.predict(X_testset)\nprint('Decision Tree Jaccard index: {:.2f}'.format(jaccard_similarity_score(y_testset, tree_test)))\nprint('Decision Tree F1-score: {:.2f}'.format(f1_score(y_testset, tree_test, average='weighted')))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## SVM Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tree_test = loan_tree.predict(X_testset)\nprint('SVM Jaccard index: {:.2f}'.format(jaccard_similarity_score(y_testset, tree_test)))\nprint('SVM F1-score: {:.2f}'.format(f1_score(y_testset, tree_test, average='weighted')))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Logistic Regression Evaluation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LR_test = LR.predict(X_testset)\nLR_test_prob = LR.predict_proba(X_testset)\nprint('LR Jaccard index: {:.2f}'.format(jaccard_similarity_score(y_testset, LR_test)))\nprint('LR F1-score: {:.2f}'.format(f1_score(y_testset, LR_test, average='weighted')))\nprint('LR F1-score: {:.2f}'.format(log_loss(y_testset, LR_test_prob)))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Report"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}